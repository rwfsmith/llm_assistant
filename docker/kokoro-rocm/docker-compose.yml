# docker-compose.yml – Kokoro-FastAPI with ROCm (AMD GPU) support
#
# Quick start (no setup script needed):
#   export VIDEO_GID=$(getent group video | cut -d: -f3)
#   export RENDER_GID=$(getent group render | cut -d: -f3)
#   export GFX_ARCH=gfx1150   # set your GPU arch (see Dockerfile for options)
#   docker compose up -d --build
#
# The Dockerfile clones Kokoro-FastAPI source at build time.
# On rebuild: docker compose build --no-cache

name: kokoro-rocm

services:
  kokoro-tts:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        ROCM_VERSION: "7.2"
        GFX_ARCH: ${GFX_ARCH:-}
        KOKORO_REF: master

    container_name: kokoro-tts-rocm

    restart: unless-stopped

    # Run as root so the container can write to the host-mounted volume.
    # The Dockerfile creates appuser (uid 1001) but mounted dirs are root-owned.
    user: root

    ports:
      - "8880:8880"

    # --- AMD GPU passthrough ---
    devices:
      - /dev/dri   # GPU render nodes (e.g. /dev/dri/renderD128)
      - /dev/kfd   # ROCm kernel fusion driver

    group_add:
      # Group IDs for: video (44), render (109 on most distros – check with
      # `getent group render | cut -d: -f3`). Override with env vars if needed.
      - "${VIDEO_GID:-44}"
      - "${RENDER_GID:-109}"

    environment:
      - USE_GPU=true
      - DEVICE=gpu
      - DOWNLOAD_MODEL=true
      - PYTHONUNBUFFERED=1
      # ROCm performance tuning
      - TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1
      # MIOpen kernel tuning – required on first run for any GPU without pre-built kdb files.
      # Runs an exhaustive kernel search and writes results to the miopen-cache volume.
      # After first successful startup, change these to MIOPEN_FIND_MODE=2 (use cache only).
      - MIOPEN_FIND_MODE=3
      - MIOPEN_FIND_ENFORCE=3
      #
      # gfx1150 (Ryzen AI 9 HX 370, Strix Point) – setup.sh injects native gfx1150
      # PyTorch staging wheels from rocm.nightlies.amd.com. No HSA override needed.

    volumes:
      # Model weights – avoids re-downloading on container recreate
      - ./data/models:/app/api/src/models/v1_0
      # MIOpen kernel shape cache (speeds up RDNA 2 inference after first run)
      - ./data/miopen-config:/root/.config/miopen
      - ./data/miopen-cache:/root/.cache/miopen

    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8880/v1/audio/voices"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # Optional: limit to a specific GPU by PCI bus ID
    # Uncomment and adjust if you have multiple AMD GPUs:
    # environment:
    #   - ROCR_VISIBLE_DEVICES=0

  # ---------------------------------------------------------------------------
  # Wyoming protocol proxy – exposes Kokoro-FastAPI as a Wyoming TTS service
  # so Home Assistant can use it via the built-in Wyoming integration on
  # port 10200 (TCP), in addition to the OpenAI-compatible HTTP API.
  # ---------------------------------------------------------------------------
  kokoro-wyoming:
    build:
      context: ./wyoming
      dockerfile: Dockerfile

    container_name: kokoro-wyoming

    restart: unless-stopped

    ports:
      - "10200:10200"

    depends_on:
      kokoro-tts:
        condition: service_healthy

    environment:
      # URL of the Kokoro-FastAPI service (internal Docker network name)
      - KOKORO_URL=http://kokoro-tts:8880
      # Default voice when the client does not request a specific one
      - DEFAULT_VOICE=${KOKORO_DEFAULT_VOICE:-af_bella}
      - DEFAULT_SPEED=${KOKORO_DEFAULT_SPEED:-1.0}

    command: >
      --kokoro-url http://kokoro-tts:8880
      --voice ${KOKORO_DEFAULT_VOICE:-af_bella}
      --speed ${KOKORO_DEFAULT_SPEED:-1.0}
